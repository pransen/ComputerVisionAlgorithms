{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background Extraction from videos using Gaussian Mixture Models\n",
    "\n",
    "**Objective**  \n",
    "Given a video with sparse and dynamically changing foreground, extract the static background.\n",
    "\n",
    "**Input:**  \n",
    "![](./resources/traffic.gif)\n",
    "\n",
    "**Expected Output:**  \n",
    "![](./resources/background.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture('./data/traffic.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm:**  \n",
    "The step-wise approach is as follows:\n",
    "1. Extract frames from the video.\n",
    "2. Stack the frames in an array where the final array dimensions will be *(num_frames, image_width, image_height, num_channels)*\n",
    "3. Initialize a dummy background image of the same size as that of the individual frames.\n",
    "4. For each point characterized by the x coordinate, the y-coordinate and the channel, model the intensity value across all the frames as a mixture of two Gaussians.\n",
    "5. Once modelled, initialize the intensity value at the corresponding location in the dummy background image with the mean of the most weighted cluster. The most weighted cluster will be the one coming from the background whereas owing to the dynamically changing and sparse nature of the foreground, the other cluster will be voted less.\n",
    "6. Finally, the background image will contain the intensity values corresponding to the static background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = vid.read()\n",
    "    if frame is not None:\n",
    "        frames.append(frame)\n",
    "        frame_count += 1\n",
    "    else:\n",
    "        break\n",
    "frames = np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of frames extracted is {}\".format(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"array dimensions will be (num_frames, image_width, image_height, num_channels)\")\n",
    "print(\"Shape of frames is {}\".format(frames.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Modelling:**  \n",
    "We are going to model each point in space for all the three image channels, namely **R**, **G** and **B** as a bimodal distribution of Gaussians, where one Gaussian in the mixture accounts for the background and the other for the foreground."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a dummy background image with all zeros\n",
    "background = np.zeros(shape=(frames.shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dummy background image is {}\".format(background.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(frames.shape[1]):\n",
    "    for j in range(frames.shape[2]):\n",
    "        for k in range(frames.shape[3]):\n",
    "            X = frames[:, i, j, k]\n",
    "            X = X.reshape(X.shape[0], 1)\n",
    "            gmm.fit(X)\n",
    "            means = gmm.means_\n",
    "            covars = gmm.covariances_\n",
    "            weights = gmm.weights_\n",
    "            idx = np.argmax(weights)\n",
    "            background[i][j][k] = int(means[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the result onto disc\n",
    "cv2.imwrite('background.png', background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
